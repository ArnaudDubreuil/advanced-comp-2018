{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Work on this before the next lecture on 12 April. We will talk about questions, comments, and solutions during the exercise after the third lecture.\n",
    "\n",
    "Please do form study groups! When you do, make sure you can explain everything in your own words, do not simply copy&paste from others.\n",
    "\n",
    "The solutions to a lot of these problems can probably be found with Google. Please don't. You will not learn a lot by copy&pasting from the internet.\n",
    "\n",
    "If you want to get credit/examination on this course please upload your work to your GitHub repository for this course before the next lecture starts and post a link to your repository in [this thread](https://github.com/wildtreetech/advanced-computing-2018/issues/3). If you worked on things together with others please add their names to the notebook so we can see who formed groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Build your own random forest classifier! Using the `DecisionTreeClassifier` from scikit-learn (http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) construct your own `RandomForestClassifier`.\n",
    "\n",
    "There are two methods for adding randomisation to the tree growing process:\n",
    "\n",
    "* grow each tree on a bootstrap sample of the data\n",
    "* configure each tree to select a subset of features for each split\n",
    "\n",
    "Try out your new `RandomForestClassifier` on the https://archive.ics.uci.edu/ml/datasets/bank+marketing dataset.\n",
    "\n",
    "**Note:** To test your classifier it is a good idea to use a smaller dataset like the `make_blobs` from the lecture. It will run much faster and be easier to debug.\n",
    "\n",
    "* Can you show that a forest of trees that are all the same performs like a single decision tree?\n",
    "* Can you compute the correlation coefficient between scores assigned by two different trees in the forest? In order to gain from buildign a forest you want your trees to not be 100% correlated. Experiment with the different randomisation strategies to check that they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for RFC with diff trees: 0.8886087148860872\n",
      "Testing score for RFC with diff trees: 0.8843227461735822\n",
      "Training score for 1 tree: 0.8855120548551205\n",
      "Testing score for 1 tree: 0.883791913651243\n",
      "Training score for RFC with same trees (equal to score with only 1 tree): 0.8855120548551205\n",
      "Testing score for RFC with same trees (equal to score with only 1 tree): 0.883791913651243\n",
      "Training score for first tree in the RFC 0.8855120548551205\n",
      "Training score for second tree in the RFC 0.8886087148860872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/numpy/lib/function_base.py:3175: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/numpy/lib/function_base.py:3109: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  c *= 1. / np.float64(fact)\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/numpy/lib/function_base.py:3109: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= 1. / np.float64(fact)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "from numpy import corrcoef\n",
    "from utils import draw_tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#X, y = make_blobs(n_samples=400, centers=23, random_state=42)#Shoud change this to something from the bankDS\n",
    "#y = np.take(labels, (y < 10))\n",
    "#plt.scatter(X[:, 0], X[:, 1], c=y, lw=0)\n",
    "#plt.xlabel(\"Feature 1\")\n",
    "#plt.ylabel(\"Feature 2\")\n",
    "\n",
    "data=pd.read_csv(\"bankDS/bank-full.csv\", sep=\";\")#Loading the bank dataset with pandas\n",
    "for column in data.columns:#Label encoder to convert the string data into appriopriate type\n",
    "    if data[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "\n",
    "X = data.iloc[:, 0:15].values  # select columns 1 through 16\n",
    "y = data.iloc[:, 16].values   # select column 17\n",
    "\n",
    "labels = [\"b\", \"r\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "voting = VotingClassifier([('tree1',DecisionTreeClassifier(max_leaf_nodes=6, min_samples_split=3, random_state=1)),\n",
    "                           ('tree2',DecisionTreeClassifier(max_leaf_nodes=12, random_state=2))],\n",
    "                          voting='soft', flatten_transform=True)\n",
    "voting.fit(X_train, y_train)\n",
    "print(\"Training score for RFC with diff trees:\", voting.score(X_train, y_train))\n",
    "print(\"Testing score for RFC with diff trees:\", voting.score(X_test, y_test))\n",
    "\n",
    "#Can you show that a forest of trees that are all the same performs like a single decision tree?\n",
    "#As seen below, the scores from 1 single tree is indeed the same than the score from a voting including two times\n",
    "#this tree as two \"different\" (but indeed identical) trees.\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=5, min_samples_split=3, random_state=1).fit(X_train, y_train)\n",
    "print(\"Training score for 1 tree:\", tree.score(X_train, y_train))\n",
    "print(\"Testing score for 1 tree:\", tree.score(X_test, y_test))\n",
    "\n",
    "voting = VotingClassifier([('tree1',DecisionTreeClassifier(max_leaf_nodes=5, min_samples_split=3, random_state=1)),\n",
    "                           ('tree2',DecisionTreeClassifier(max_leaf_nodes=5, min_samples_split=3, random_state=1))],\n",
    "                          voting='soft', flatten_transform=True)\n",
    "voting.fit(X_train, y_train)\n",
    "print(\"Training score for RFC with same trees (equal to score with only 1 tree):\", voting.score(X_train, y_train))\n",
    "print(\"Testing score for RFC with same trees (equal to score with only 1 tree):\", voting.score(X_test, y_test))\n",
    "\n",
    "#Can you compute the correlation coefficient between scores assigned by two different trees in the forest? \n",
    "#In order to gain from buildign a forest you want your trees to not be 100% correlated. \n",
    "#Experiment with the different randomisation strategies to check that they work.\n",
    "voting = VotingClassifier([('tree1',DecisionTreeClassifier(max_leaf_nodes=6, min_samples_split=3, random_state=1)),\n",
    "                           ('tree2',DecisionTreeClassifier(max_leaf_nodes=12, random_state=2))],\n",
    "                          voting='soft', flatten_transform=True)\n",
    "tree1=DecisionTreeClassifier(max_leaf_nodes=6, min_samples_split=3, random_state=1).fit(X_train, y_train)\n",
    "tree2=DecisionTreeClassifier(max_leaf_nodes=12, random_state=2).fit(X_train, y_train)\n",
    "print(\"Training score for first tree in the RFC\", tree1.score(X_train, y_train))\n",
    "print(\"Training score for second tree in the RFC\", tree2.score(X_train, y_train))\n",
    "corrcoef(tree1.score(X_train, y_train),tree2.score(X_train, y_train))\n",
    "#Stuck here because argument for correlation coeff should be array. But scores are float... ??\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Use the ready made `RandomForestClassifier` from scikit-learn to create the best model you can for the Bank Marketing dataset. Use `GridSearchCV` (or any other method) to tune your model and possible pre-processing steps. Make sure you have a test set to use after you are done tuning to estimate your generalisation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.898\n",
      "best parameters: {'n_estimators': 15}\n",
      "test-set score: 0.895\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-12f657effdfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#rfc = rfc.fit(X,y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#print(\"Training score for RFC:\", rfc.score(X_train, y_train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing score for RFC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction for RFC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \"\"\"\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils import draw_tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"bankDS/bank-full.csv\", sep=\";\")#Loading the bank dataset with pandas\n",
    "for column in data.columns:#Label encoder to convert the string data into appriopriate type\n",
    "    if data[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "        \n",
    "#bankFeatures = list(data.columns.values)\n",
    "        \n",
    "X = data.iloc[:, 0:15].values  # select columns 1 through 16\n",
    "y = data.iloc[:, 16].values   # select column 17\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "param_grid = {'n_estimators':  np.arange(1, 20, 2)}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=17)\n",
    "#rfc = rfc.fit(X,y)\n",
    "#print(\"Training score for RFC:\", rfc.score(X_train, y_train))\n",
    "print(\"Testing score for RFC:\", rfc.score(X_test, y_test))\n",
    "print(\"Prediction for RFC:\", rfc.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Compare the feature importances calculated by a `RandomForestClassifier`, `ExtraTreesClassifier` and `GradientBoostedTreesClassifier` on the california housing dataset. You might have to tune `n_estimators` and other hyper-parameters to get good performance.\n",
    "\n",
    "Plot each of the features as a scatter plot with the target to learn about each variable. You can also make a plot of two features and use the target as colour.\n",
    "\n",
    "Fit a model and tune the model complexity using a training and test data set.\n",
    "\n",
    "Explore the feature importances and partial dependences that are important to the house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.california_housing import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "cal_housing = fetch_california_housing()\n",
    "\n",
    "# if the above doesn't work, download `cal_housing_py3.pkl` from the GitHub repository\n",
    "# and adjust the path to the downloaded file which is passed to `load()`\n",
    "# uncomment the following lines\n",
    "#from sklearn.externals.joblib import load\n",
    "#d = load('/home/username/Downloads/cal_housing_py3.pkz')\n",
    "#X, y = d[:,1:], d[:,0]/100000\n",
    "#X[:, 2] /= X[:, 5]\n",
    "#X[:, 3] /= X[:, 5]\n",
    "#X[:, 5] = X[:, 4] / X[:, 5]\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Competition time! Use any model you want (and understand) to make the best model you can to predict the target in the below dataset.\n",
    "\n",
    "Each student's submission will be ranked by:\n",
    "* their performance (using [AUC ROC](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) as metric) and\n",
    "* how well they did at predicting their generalisation error.\n",
    "\n",
    "Your final rank will be the average of your two ranks.\n",
    "\n",
    "To evaluate how good you did at predicting your generalisation error Tim will release a fresh test data set after the hand-in deadline. You can then re-run your trained classifier on that data and score its performance. We will rank students by the difference between that score and their predicted score.\n",
    "\n",
    "You can read in the data using the `pandas` library. The final column of the file contains the target (zero or one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 31, saw 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e2fbe2a704d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# you might have to adjust the path to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"challenge-train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf_original\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_original\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arnaud/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11138)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:11884)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas/_libs/parsers.c:11755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas/_libs/parsers.c:28765)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 31, saw 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils import draw_tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# you might have to adjust the path to the dataset\n",
    "df_original = pd.read_csv(\"challenge-train.csv\", header=None)\n",
    "df_original.head()\n",
    "df_train = df_original.drop([46], axis=1)\n",
    "df_train.head()\n",
    "break\n",
    "X = df_train.iloc[:, 0:15].values\n",
    "y = df_train.iloc[:, 16].values\n",
    "\n",
    "labels = [\"b\", \"r\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=17)\n",
    "rfc = rfc.fit(X,y)\n",
    "print(\"Training score for RFC:\", rfc.score(X_train, y_train))\n",
    "print(\"Testing score for RFC:\", rfc.score(X_test, y_test))\n",
    "print(\"Prediction for RFC:\", rfc.predict(X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the pandas dataframe to a numpy array\n",
    "# make sure you do not include the final column\n",
    "# in your training data (X) but store it as target (y)\n",
    "X = df_train.as_matrix()[:, :-1]\n",
    "y = df_train.as_matrix()[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
