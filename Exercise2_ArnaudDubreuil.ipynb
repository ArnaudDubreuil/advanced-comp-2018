{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Work on this before the next lecture on 12 April. We will talk about questions, comments, and solutions during the exercise after the third lecture.\n",
    "\n",
    "Please do form study groups! When you do, make sure you can explain everything in your own words, do not simply copy&paste from others.\n",
    "\n",
    "The solutions to a lot of these problems can probably be found with Google. Please don't. You will not learn a lot by copy&pasting from the internet.\n",
    "\n",
    "If you want to get credit/examination on this course please upload your work to your GitHub repository for this course before the next lecture starts and post a link to your repository in [this thread](https://github.com/wildtreetech/advanced-computing-2018/issues/3). If you worked on things together with others please add their names to the notebook so we can see who formed groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Build your own random forest classifier! Using the `DecisionTreeClassifier` from scikit-learn (http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) construct your own `RandomForestClassifier`.\n",
    "\n",
    "There are two methods for adding randomisation to the tree growing process:\n",
    "\n",
    "* grow each tree on a bootstrap sample of the data\n",
    "* configure each tree to select a subset of features for each split\n",
    "\n",
    "Try out your new `RandomForestClassifier` on the https://archive.ics.uci.edu/ml/datasets/bank+marketing dataset.\n",
    "\n",
    "**Note:** To test your classifier it is a good idea to use a smaller dataset like the `make_blobs` from the lecture. It will run much faster and be easier to debug.\n",
    "\n",
    "* Can you show that a forest of trees that are all the same performs like a single decision tree?\n",
    "* Can you compute the correlation coefficient between scores assigned by two different trees in the forest? In order to gain from buildign a forest you want your trees to not be 100% correlated. Experiment with the different randomisation strategies to check that they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score for RFC with diff trees: 0.8886087148860872\n",
      "Testing score for RFC with diff trees: 0.8843227461735822\n",
      "Training score for 1 tree: 0.8855120548551205\n",
      "Testing score for 1 tree: 0.883791913651243\n",
      "Training score for RFC with same trees (equal to score with only 1 tree): 0.8855120548551205\n",
      "Testing score for RFC with same trees (equal to score with only 1 tree): 0.883791913651243\n",
      "Training score for first tree in the RFC 0.8855120548551205\n",
      "Training score for second tree in the RFC 0.8886087148860872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/numpy/lib/function_base.py:3175: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar)\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/numpy/lib/function_base.py:3109: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  c *= 1. / np.float64(fact)\n",
      "/home/arnaud/anaconda2/envs/ATC2018/lib/python3.6/site-packages/numpy/lib/function_base.py:3109: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= 1. / np.float64(fact)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan],\n",
       "       [nan, nan]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "from numpy import corrcoef\n",
    "from utils import draw_tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#X, y = make_blobs(n_samples=400, centers=23, random_state=42)#Shoud change this to something from the bankDS\n",
    "#y = np.take(labels, (y < 10))\n",
    "#plt.scatter(X[:, 0], X[:, 1], c=y, lw=0)\n",
    "#plt.xlabel(\"Feature 1\")\n",
    "#plt.ylabel(\"Feature 2\")\n",
    "\n",
    "data=pd.read_csv(\"bankDS/bank-full.csv\", sep=\";\")#Loading the bank dataset with pandas\n",
    "for column in data.columns:#Label encoder to convert the string data into appriopriate type\n",
    "    if data[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "\n",
    "X = data.iloc[:, 0:15].values  # select columns 1 through 16\n",
    "y = data.iloc[:, 16].values   # select column 17\n",
    "\n",
    "labels = [\"b\", \"r\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "voting = VotingClassifier([('tree1',DecisionTreeClassifier(max_leaf_nodes=6, min_samples_split=3, random_state=1)),\n",
    "                           ('tree2',DecisionTreeClassifier(max_leaf_nodes=12, random_state=2))],\n",
    "                          voting='soft', flatten_transform=True)\n",
    "voting.fit(X_train, y_train)\n",
    "print(\"Training score for RFC with diff trees:\", voting.score(X_train, y_train))\n",
    "print(\"Testing score for RFC with diff trees:\", voting.score(X_test, y_test))\n",
    "\n",
    "#Can you show that a forest of trees that are all the same performs like a single decision tree?\n",
    "#As seen below, the scores from 1 single tree is indeed the same than the score from a voting including two times\n",
    "#this tree as two \"different\" (but indeed identical) trees.\n",
    "tree = DecisionTreeClassifier(max_leaf_nodes=5, min_samples_split=3, random_state=1).fit(X_train, y_train)\n",
    "print(\"Training score for 1 tree:\", tree.score(X_train, y_train))\n",
    "print(\"Testing score for 1 tree:\", tree.score(X_test, y_test))\n",
    "\n",
    "voting = VotingClassifier([('tree1',DecisionTreeClassifier(max_leaf_nodes=5, min_samples_split=3, random_state=1)),\n",
    "                           ('tree2',DecisionTreeClassifier(max_leaf_nodes=5, min_samples_split=3, random_state=1))],\n",
    "                          voting='soft', flatten_transform=True)\n",
    "voting.fit(X_train, y_train)\n",
    "print(\"Training score for RFC with same trees (equal to score with only 1 tree):\", voting.score(X_train, y_train))\n",
    "print(\"Testing score for RFC with same trees (equal to score with only 1 tree):\", voting.score(X_test, y_test))\n",
    "\n",
    "#Can you compute the correlation coefficient between scores assigned by two different trees in the forest? \n",
    "#In order to gain from buildign a forest you want your trees to not be 100% correlated. \n",
    "#Experiment with the different randomisation strategies to check that they work.\n",
    "voting = VotingClassifier([('tree1',DecisionTreeClassifier(max_leaf_nodes=6, min_samples_split=3, random_state=1)),\n",
    "                           ('tree2',DecisionTreeClassifier(max_leaf_nodes=12, random_state=2))],\n",
    "                          voting='soft', flatten_transform=True)\n",
    "tree1=DecisionTreeClassifier(max_leaf_nodes=6, min_samples_split=3, random_state=1).fit(X_train, y_train)\n",
    "tree2=DecisionTreeClassifier(max_leaf_nodes=12, random_state=2).fit(X_train, y_train)\n",
    "print(\"Training score for first tree in the RFC\", tree1.score(X_train, y_train))\n",
    "print(\"Training score for second tree in the RFC\", tree2.score(X_train, y_train))\n",
    "corrcoef(tree1.score(X_train, y_train),tree2.score(X_train, y_train))\n",
    "#Stuck here because argument for correlation coeff should be array. But scores are float... ??\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Use the ready made `RandomForestClassifier` from scikit-learn to create the best model you can for the Bank Marketing dataset. Use `GridSearchCV` (or any other method) to tune your model and possible pre-processing steps. Make sure you have a test set to use after you are done tuning to estimate your generalisation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean cross-validation score: 0.897\n",
      "best parameters: {'n_estimators': 19}\n",
      "test-set score: 0.897\n",
      "Training score for RFC: 0.9978323379783234\n",
      "Testing score for RFC: 0.9980978501282846\n",
      "Prediction for RFC: [0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# your code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from utils import draw_tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"bankDS/bank-full.csv\", sep=\";\")#Loading the bank dataset with pandas\n",
    "for column in data.columns:#Label encoder to convert the string data into appriopriate type\n",
    "    if data[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        data[column] = le.fit_transform(data[column])\n",
    "        \n",
    "#bankFeatures = list(data.columns.values)\n",
    "        \n",
    "X = data.iloc[:, 0:15].values  # select columns 1 through 16\n",
    "y = data.iloc[:, 16].values   # select column 17\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "\n",
    "param_grid = {'n_estimators':  np.arange(1, 20, 2)}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "print(\"test-set score: {:.3f}\".format(grid.score(X_test, y_test)))\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=17)\n",
    "rfc = rfc.fit(X,y)\n",
    "print(\"Training score for RFC:\", rfc.score(X_train, y_train))\n",
    "print(\"Testing score for RFC:\", rfc.score(X_test, y_test))\n",
    "print(\"Prediction for RFC:\", rfc.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Compare the feature importances calculated by a `RandomForestClassifier`, `ExtraTreesClassifier` and `GradientBoostedTreesClassifier` on the california housing dataset. You might have to tune `n_estimators` and other hyper-parameters to get good performance.\n",
    "\n",
    "Plot each of the features as a scatter plot with the target to learn about each variable. You can also make a plot of two features and use the target as colour.\n",
    "\n",
    "Fit a model and tune the model complexity using a training and test data set.\n",
    "\n",
    "Explore the feature importances and partial dependences that are important to the house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.california_housing import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "cal_housing = fetch_california_housing()\n",
    "\n",
    "# if the above doesn't work, download `cal_housing_py3.pkl` from the GitHub repository\n",
    "# and adjust the path to the downloaded file which is passed to `load()`\n",
    "# uncomment the following lines\n",
    "#from sklearn.externals.joblib import load\n",
    "#d = load('/home/username/Downloads/cal_housing_py3.pkz')\n",
    "#X, y = d[:,1:], d[:,0]/100000\n",
    "#X[:, 2] /= X[:, 5]\n",
    "#X[:, 3] /= X[:, 5]\n",
    "#X[:, 5] = X[:, 4] / X[:, 5]\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Competition time! Use any model you want (and understand) to make the best model you can to predict the target in the below dataset.\n",
    "\n",
    "Each student's submission will be ranked by:\n",
    "* their performance (using [AUC ROC](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) as metric) and\n",
    "* how well they did at predicting their generalisation error.\n",
    "\n",
    "Your final rank will be the average of your two ranks.\n",
    "\n",
    "To evaluate how good you did at predicting your generalisation error Tim will release a fresh test data set after the hand-in deadline. You can then re-run your trained classifier on that data and score its performance. We will rank students by the difference between that score and their predicted score.\n",
    "\n",
    "You can read in the data using the `pandas` library. The final column of the file contains the target (zero or one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../../data/challenge-train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b8d977e181c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# you might have to adjust the path to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/challenge-train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ATC2018/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ATC2018/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ATC2018/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ATC2018/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/ATC2018/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../../data/challenge-train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# you might have to adjust the path to the dataset\n",
    "df_train = pd.read_csv(\"../../data/challenge-train.csv\", header=None)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the pandas dataframe to a numpy array\n",
    "# make sure you do not include the final column\n",
    "# in your training data (X) but store it as target (y)\n",
    "X = df_train.as_matrix()[:, :-1]\n",
    "y = df_train.as_matrix()[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
